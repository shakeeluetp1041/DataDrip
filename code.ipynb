{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import  MinMaxScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib # Save and load preprocessing pieline and models\n",
    "import json\n",
    "# some_module.py\n",
    "from logger_setup import logger # Initialize logger: logger_setup  file is in directory above\n",
    "\n",
    "\n",
    "\n",
    "scaler_minmax= MinMaxScaler()                                                             # Create a MinMaxScaler object\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore',drop='first')            # Create a OneHotEncoder object\n",
    "\n",
    "\n",
    "# Read CSV files\n",
    "\n",
    "df=pd.read_csv(\"Training_Set_Values.csv\")       # Read the Training data CSV file\n",
    "name_featrures=df.columns                       # Get the features name\n",
    "len_features=len(name_featrures)                # Get the length of features\n",
    "labels=pd.read_csv(\"Training_Set_Labels.csv\")   # Read the labels (target) CSV file\n",
    "labels.head()\n",
    "df['target'] = labels['status_group']           # Add the target column to the dataframe\n",
    "#print(df.shape)                                 # Print the shape of the dataframe\n",
    "#df.head()\n",
    "#df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59400.000000\n",
       "mean      1300.652475\n",
       "std        951.620547\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%       1986.000000\n",
       "75%       2004.000000\n",
       "max       2013.000000\n",
       "Name: construction_year, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['construction_year'].describe()\n",
    "\n",
    "#(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['construction_year'].unique()\n",
    "df['construction_year'].value_counts()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=df['construction_year'], color='lightblue')\n",
    "sns.stripplot(x=df['construction_year'], color='black', size=3, jitter=True, alpha=0.5)\n",
    "\n",
    "plt.title('Box Plot with Data Points - GPS Height')\n",
    "plt.xlabel('GPS Height')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-2e-08)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['latitude'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping columns: (59400, 22)\n",
      "2025-06-02 18:46:40,139 - INFO - Columns dropped=['id', 'amount_tsh', 'num_private', 'subvillage', 'recorded_by', 'scheme_name', 'extraction_type_group', 'extraction_type_class', 'management', 'payment_type', 'quality_group', 'quantity_group', 'source', 'waterpoint_type_group', 'funder', 'installer', 'wpt_name', 'ward', 'scheme_management'], shape after dropping columns=(59400, 22)\n"
     ]
    }
   ],
   "source": [
    "# Columns to be dropped for the baseline models\n",
    "columns_drop=['id','amount_tsh','num_private','subvillage','recorded_by','scheme_name',\n",
    "              'extraction_type_group','extraction_type_class',\n",
    "              'management','payment_type','quality_group','quantity_group','source','waterpoint_type_group',\n",
    "              'funder','installer','wpt_name','ward','scheme_management']\n",
    "\n",
    "df = df.drop(columns=columns_drop)\n",
    "print('Shape after dropping columns:', df.shape)\n",
    "\n",
    "logger.info(f\"Columns dropped={columns_drop}, shape after dropping columns={df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target column to labels \n",
    "#print(df['target'].unique())\n",
    "target_map_dict={'functional': 2, 'functional needs repair': 1, 'non functional': 0} # Defined the mapping of labels to numbers (integers)\n",
    "#print(df['target'].head())\n",
    "df['target'] =df['target'].map(target_map_dict) # transform the target column (labels) to  numbers (integers)\n",
    "#df['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate features and target and perform train test split\n",
    "X = df.drop(columns=['target'])  # Features only\n",
    "y = df['target']                 # Target column\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.04, random_state=42, stratify=y)  # 2376 records for the test\n",
    "\n",
    "# Save test data\n",
    "joblib.dump(X_test, \"X_test.pkl\")\n",
    "joblib.dump(y_test, \"y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54918    2\n",
       "25673    0\n",
       "50464    0\n",
       "58269    0\n",
       "45655    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test), type(X_test)\n",
    "print(X_test.index.equals(y_test.index))  # should be True\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories saved to categories.json\n",
      "2025-06-02 18:46:40,936 - INFO - Traina and Test data transformed. X_train shape: (57024, 260), X_test shape: (2376, 260)\n",
      "2025-06-02 18:46:40,945 - INFO - Preprocessor saved to preprocessor.joblib\n"
     ]
    }
   ],
   "source": [
    "# Import the custom transformers form helper_function.py\n",
    "# The helper_function.py file contains the definitions for StringConverter, YearExtractor, IQRCapper, and ConstructionYearTransformer\n",
    "from helper_function import (\n",
    "    StringConverter,\n",
    "    YearExtractor,\n",
    "    IQRCapper,\n",
    "    ConstructionYearTransformer,\n",
    "    ObjectToNumericConverter\n",
    ")\n",
    "    \n",
    "#pipeline transformers\n",
    "date_recorded_transformer_pipeline=Pipeline([\n",
    "    \n",
    "    ('year_extractor',YearExtractor()),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore',drop='first'))\n",
    "])\n",
    "\n",
    "\n",
    "oulier_minmax_pipeline_clip = Pipeline(steps=[\n",
    "    ('iqr_cap', IQRCapper(strategy='clip')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "oulier_minmax_pipeline_mean = Pipeline(steps=[\n",
    "    ('iqr_cap', IQRCapper(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "oulier_minmax_pipeline_median = Pipeline(steps=[\n",
    "    ('iqr_cap', IQRCapper(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "     ('string_converter', StringConverter()),\n",
    "    #('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('ohe', OneHotEncoder(sparse_output=False, handle_unknown='ignore',drop='first'))\n",
    "])\n",
    "\n",
    "constructionyear_pipeline = Pipeline(steps=[\n",
    "    ('replace_zeros_with_median', ConstructionYearTransformer()),\n",
    "    ('minmax_scaling', MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_columns=['basin','region','region_code','district_code','lga','public_meeting','permit','extraction_type',\n",
    "                                    'management_group','payment','water_quality','quantity','source_type','source_class',\n",
    "                                    'waterpoint_type']\n",
    "# Extract unique categories for each categorical column\n",
    "categories = {}\n",
    "for col in categorical_columns:\n",
    "    unique_categories = df[col].unique().tolist()\n",
    "    # Convert to string and remove None if needed (NaN will be handled by pipeline)\n",
    "    categories[col] = sorted(unique_categories)\n",
    "\n",
    "# Save categories to a JSON file\n",
    "with open(\"categories.json\", \"w\") as f:\n",
    "    json.dump(categories, f, indent=2)\n",
    "\n",
    "print(\"Categories saved to categories.json\")\n",
    "\n",
    "# ColumnTransformer and full pipeline setup for feature preprocessing\n",
    "# The ColumnTransformer allows us to apply different preprocessing steps to different columns of the DataFrame\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('date', date_recorded_transformer_pipeline, ['date_recorded']),\n",
    "        #('gps_height', scaler_minmax, ['gps_height']),\n",
    "        ('outlier_minmax_gps_height', oulier_minmax_pipeline_mean, ['gps_height']),\n",
    "        ('outlier_minmax_longitude', oulier_minmax_pipeline_mean, ['longitude']),\n",
    "        ('outlier_minmax_latitude', oulier_minmax_pipeline_mean, ['latitude']),\n",
    "         ('cat_ohe', cat_pipeline, categorical_columns),\n",
    "        ('outlier_minmax_population', oulier_minmax_pipeline_clip, ['population']),\n",
    "        ('constructionyear', constructionyear_pipeline, ['construction_year'])\n",
    "\n",
    "\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('object_to_numeric', ObjectToNumericConverter())  # your custom step\n",
    "])\n",
    "\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "logger.info(f\"Traina and Test data transformed. X_train shape: {X_train_transformed.shape}, X_test shape: {X_test_transformed.shape}\")\n",
    "# Save the preprocessor (this is done only once)\n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
    "logger.info(\"Preprocessor saved to preprocessor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 18:46:40,962 - INFO - Training model: DecisionTree\n",
      "2025-06-02 18:46:43,854 - INFO - Model DecisionTree trained successfully.\n",
      "2025-06-02 18:46:43,857 - INFO - Model DecisionTree saved to DecisionTree_model.joblib\n",
      "2025-06-02 18:46:43,918 - INFO - Training model: RandomForest\n",
      "2025-06-02 18:46:59,805 - INFO - Model RandomForest trained successfully.\n",
      "2025-06-02 18:46:59,889 - INFO - Model RandomForest saved to RandomForest_model.joblib\n",
      "2025-06-02 18:47:01,439 - INFO - Training model: XGBoost\n",
      "2025-06-02 18:47:08,924 - INFO - Model XGBoost trained successfully.\n",
      "2025-06-02 18:47:08,983 - INFO - Model XGBoost saved to XGBoost_model.joblib\n",
      "\n",
      "Model Comparison:\n",
      "Model           Train Acc       Test Acc       \n",
      "---------------------------------------------\n",
      "DecisionTree    0.7672          0.7496         \n",
      "RandomForest    0.8141          0.7765         \n",
      "XGBoost         0.8607          0.8068         \n",
      "\n",
      "Top 10 Important Features:\n",
      "\n",
      "DecisionTree:\n",
      "waterpoint_type_other          0.2024\n",
      "quantity_seasonal              0.1305\n",
      "quantity_enough                0.1124\n",
      "quantity_insufficient          0.0861\n",
      "longitude                      0.0624\n",
      "construction_year              0.0595\n",
      "latitude                       0.0408\n",
      "waterpoint_type_communal standpipe multiple 0.0378\n",
      "population                     0.0175\n",
      "gps_height                     0.0145\n",
      "\n",
      "RandomForest:\n",
      "quantity_enough                0.0745\n",
      "longitude                      0.0676\n",
      "waterpoint_type_other          0.0663\n",
      "latitude                       0.0649\n",
      "construction_year              0.0643\n",
      "extraction_type_other          0.0635\n",
      "gps_height                     0.0393\n",
      "population                     0.0301\n",
      "quantity_insufficient          0.0257\n",
      "waterpoint_type_communal standpipe 0.0256\n",
      "\n",
      "XGBoost:\n",
      "waterpoint_type_other          0.0560\n",
      "quantity_seasonal              0.0248\n",
      "lga_Bariadi                    0.0229\n",
      "region_code_11                 0.0223\n",
      "extraction_type_other          0.0194\n",
      "region_Iringa                  0.0188\n",
      "lga_Kigoma Rural               0.0123\n",
      "region_code_18                 0.0119\n",
      "lga_Rombo                      0.0113\n",
      "region_code_17                 0.0109\n"
     ]
    }
   ],
   "source": [
    "# models (Decision Tree, Random Forest, XGBoost) to be used\n",
    "models = {    \n",
    "    \"DecisionTree\": DecisionTreeClassifier(\n",
    "        max_depth=10,  # You can tune this\n",
    "        random_state=42\n",
    "    ),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,  # You can tune this too\n",
    "        random_state=42\n",
    "    ),\"XGBoost\": XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=11,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        #use_label_encoder=False,\n",
    "        eval_metric='mlogloss',    # good for multi-class\n",
    "        objective='multi:softmax', # directly outputs class labels\n",
    "        num_class=3,               # number of target classes\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Results and feature importances storage\n",
    "results = {}\n",
    "feature_importances = {}\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    logger.info(f\"Training model: {name}\")\n",
    "    model.fit(X_train_transformed, y_train)  # Fit the model on the transformed training data\n",
    "    logger.info(f\"Model {name} trained successfully.\")\n",
    "    # Save the trained model for later use\n",
    "    joblib.dump(model, f\"{name}_model.joblib\")\n",
    "    logger.info(f\"Model {name} saved to {name}_model.joblib\")\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_transformed)\n",
    "    y_test_pred =  model.predict(X_test_transformed)\n",
    "\n",
    "    # Accuracy scores\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    results[name] = {\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Test Accuracy\": test_accuracy\n",
    "    }\n",
    "    \n",
    "    # Extract feature importances  \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Get transformed feature names from preprocessor\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        importances = model.feature_importances_\n",
    "        feature_importances[name] = sorted(\n",
    "            zip(feature_names, importances),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(\"{:<15} {:<15} {:<15}\".format(\"Model\", \"Train Acc\", \"Test Acc\"))\n",
    "print(\"-\" * 45)\n",
    "for model_name, scores in results.items():\n",
    "    print(\"{:<15} {:<15.4f} {:<15.4f}\".format(model_name, scores[\"Train Accuracy\"], scores[\"Test Accuracy\"]))\n",
    "\n",
    "# Print top features\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "for model_name, importance_list in feature_importances.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for feature, importance in importance_list[:10]:\n",
    "        print(f\"{feature:<30} {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel Comparison:\\nModel           Train Acc       Test Acc       \\n---------------------------------------------\\nDecision Tree   0.7672          0.7496         \\nRandom Forest   0.8141          0.7765         \\nXGBoost         0.8607          0.8068  \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model Comparison:\n",
    "Model           Train Acc       Test Acc       \n",
    "---------------------------------------------\n",
    "Decision Tree   0.7672          0.7496         \n",
    "Random Forest   0.8141          0.7765         \n",
    "XGBoost         0.8607          0.8068  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2004\\1964544937.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Result={'Index': random_index,'True label': int(y_test_sample), 'Predicted label': int(y_test_sample_pred)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>True label</th>\n",
       "      <th>Predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>877</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  True label  Predicted label\n",
       "0    877           2                2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model on one sample form the test data\n",
    "import random\n",
    "\n",
    "# Load preprocessor and a trained model (e.g., RandomForest)\n",
    "preprocessor = joblib.load(\"preprocessor.joblib\")\n",
    "model = joblib.load(\"RandomForest_model.joblib\")  # Change to desired model: let say I chose RandomForest form list: [DecisionTree, RandomForest and XGBoost]\n",
    "# Pick a random index from the test set\n",
    "random_index = random.randint(0, len(X_test) - 1)\n",
    "X_test_sample=X_test.iloc[[random_index]]  # extra [] is sued to get the dataframe not a series as our pipeline expects dataframe as input\n",
    "y_test_sample=y_test.iloc[random_index]\n",
    "# Preprocess the test sample\n",
    "X_test_sample_transformed = preprocessor.transform(X_test_sample)\n",
    "y_test_sample_pred = model.predict(X_test_sample_transformed)\n",
    "\n",
    "Result={'Index': random_index,'True label': int(y_test_sample), 'Predicted label': int(y_test_sample_pred)}\n",
    "Result_df = pd.DataFrame([Result])\n",
    "Result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>lga</th>\n",
       "      <th>population</th>\n",
       "      <th>...</th>\n",
       "      <th>permit</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>2011-04-03</td>\n",
       "      <td>0</td>\n",
       "      <td>33.88389</td>\n",
       "      <td>-9.259478</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>Rungwe</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>parastatal</td>\n",
       "      <td>unknown</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_recorded  gps_height  longitude  latitude       basin region  \\\n",
       "12599    2011-04-03           0   33.88389 -9.259478  Lake Nyasa  Mbeya   \n",
       "\n",
       "       region_code  district_code     lga  population  ... permit  \\\n",
       "12599           12              4  Rungwe           0  ...    NaN   \n",
       "\n",
       "      construction_year  extraction_type management_group  payment  \\\n",
       "12599                 0          gravity       parastatal  unknown   \n",
       "\n",
       "      water_quality quantity source_type source_class     waterpoint_type  \n",
       "12599          soft   enough      spring  groundwater  communal standpipe  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.03146853, 0.39828083, 0.20515685,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.75471698]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sample_transformed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
